{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsseSr1P8_y2"
   },
   "source": [
    "# Books Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8f4af668"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "import requests\n",
    "import psycopg2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e83e76c"
   },
   "outputs": [],
   "source": [
    "DB_HOST = \"isrpeer.ctw842oc69v3.us-east-2.rds.amazonaws.com\"\n",
    "DB_NAME = \"isr_books\"\n",
    "DB_USER = \"isr_peer\"\n",
    "DB_PASS = \"ISRpeer2024\"\n",
    "\n",
    "def connect():\n",
    "    conn_string = \"host=\"+ DB_HOST +\" port=\"+ \"5432\" +\" dbname=\"+ DB_NAME +\" user=\" + DB_USER+\" password=\"+ DB_PASS\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    print(\"Connected!\")\n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8e9f836",
    "outputId": "bc7a0a63-1847-4fcc-ade1-4f8f248e2589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "conn, cursor = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0DDNIwD8jee"
   },
   "outputs": [],
   "source": [
    "# Creating Data Table 'new_merged_books' in the database\n",
    "def create_table(DB_HOST, DB_NAME, DB_USER, DB_PASS, cursor):\n",
    "\n",
    "    # SQL command to create a table\n",
    "    create_table_command = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS new_merged_books (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        Title VARCHAR(255),\n",
    "        Author TEXT,\n",
    "        Publisher VARCHAR(255),\n",
    "        PublishedDate VARCHAR(20),\n",
    "        Description TEXT,\n",
    "        PrintType VARCHAR(50),\n",
    "        AverageRating REAL,\n",
    "        Category TEXT,\n",
    "        MaturityRating VARCHAR(50),\n",
    "        InfoLink TEXT,\n",
    "        IndustryIdentifiers TEXT,\n",
    "        ReadingModes TEXT,\n",
    "        PageCount INT,\n",
    "        RatingsCount INT,\n",
    "        ImageLinks TEXT,\n",
    "        PreviewLink TEXT,\n",
    "        Language VARCHAR(10),\n",
    "        ListPrice REAL,\n",
    "        RetailPrice REAL,\n",
    "        BuyLink TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the SQL command\n",
    "    cursor.execute(create_table_command)\n",
    "    conn.commit()  # Commit the changes to the database\n",
    "\n",
    "\n",
    "    print(\"Table created successfully\")\n",
    "\n",
    "create_table(DB_HOST, DB_NAME, DB_USER, DB_PASS, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egXDeLvB8pHo"
   },
   "outputs": [],
   "source": [
    "# Data Retrieval from Google Books API\n",
    "# Function to extract and insert book data\n",
    "def extract_and_insert_book_data(book, cursor):\n",
    "    volume_info = book.get('volumeInfo', {})\n",
    "    sale_info = book.get('saleInfo', {})\n",
    "    book_data = (\n",
    "        volume_info.get('title'),\n",
    "        ', '.join(volume_info.get('authors', [])),\n",
    "        volume_info.get('publisher'),\n",
    "        volume_info.get('publishedDate'),\n",
    "        volume_info.get('description'),\n",
    "        volume_info.get('printType'),\n",
    "        volume_info.get('averageRating'),\n",
    "        ', '.join(volume_info.get('categories', [])),\n",
    "        volume_info.get('maturityRating'),\n",
    "        volume_info.get('infoLink'),\n",
    "        ', '.join([f\"{id['type']}: {id['identifier']}\" for id in volume_info.get('industryIdentifiers', [])]),\n",
    "        str(volume_info.get('readingModes', {})),\n",
    "        volume_info.get('pageCount'),\n",
    "        volume_info.get('ratingsCount'),\n",
    "        ', '.join(volume_info.get('imageLinks', {}).values()),\n",
    "        volume_info.get('previewLink'),\n",
    "        volume_info.get('language'),\n",
    "        sale_info.get('listPrice', {}).get('amount'),\n",
    "        sale_info.get('retailPrice', {}).get('amount'),\n",
    "        sale_info.get('buyLink')\n",
    "    )\n",
    "    insert_query = '''\n",
    "    INSERT INTO new_merged_books (\n",
    "        Title, Author, Publisher, PublishedDate, Description, PrintType, AverageRating,\n",
    "        Category, MaturityRating, InfoLink, IndustryIdentifiers, ReadingModes, PageCount,\n",
    "        RatingsCount, ImageLinks, PreviewLink, Language, ListPrice, RetailPrice, BuyLink\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    '''\n",
    "    cursor.execute(insert_query, book_data)\n",
    "\n",
    "# Function to search and store books\n",
    "def search_books(query, max_books=4000):\n",
    "    #conn = connect()\n",
    "    print(\"after connect\")\n",
    "    #cursor = conn.cursor()\n",
    "    api_key = \"Your API Key\"\n",
    "    books_data = []\n",
    "    inserted = 0\n",
    "    start_index = 0\n",
    "    max_results = 10\n",
    "\n",
    "    total_books_to_fetch = 100\n",
    "\n",
    "\n",
    "    while start_index < total_books_to_fetch:\n",
    "      api_url = f'https://www.googleapis.com/books/v1/volumes?q={query}&maxResults={max_results}&startIndex={start_index}&key={api_key}'\n",
    "      response = requests.get(api_url)\n",
    "      data = response.json()\n",
    "      books = data.get('items', [])\n",
    "      if not books:\n",
    "        break\n",
    "      books_data.extend(books)\n",
    "      for book in books:\n",
    "        extract_and_insert_book_data(book, cursor)\n",
    "      conn.commit()\n",
    "      start_index += 1\n",
    "\n",
    "\n",
    "\n",
    "search_books(\"Search Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPQs-WMS9JDm"
   },
   "outputs": [],
   "source": [
    "#Complexity Level Classification\n",
    "import psycopg2\n",
    "from textstat import textstat\n",
    "\n",
    "# Define the keywords for classification\n",
    "keywords = {\n",
    "    'Beginner': ['introduction', 'fundamentals', 'basics', 'beginner', 'overview', '101', 'introductory', 'start', 'for beginners', 'no prior knowledge', 'essential', 'first steps'],\n",
    "    'Intermediate': ['intermediate', 'beyond basics', 'develop skills', 'enhanced', 'expanded', 'practical application', 'skills improvement', 'next level', 'deepen', 'more depth', 'comprehensive'],\n",
    "    'Advanced': ['advanced', 'expert', 'mastery', 'specialized', 'complex', 'in-depth', 'intensive', 'advanced techniques', 'professional', 'expertise']\n",
    "}\n",
    "\n",
    "# Complexity calculation functions\n",
    "def classify_by_keywords(text, keywords):\n",
    "    text = text.lower()\n",
    "    for level, keys in keywords.items():\n",
    "        if any(key in text for key in keys):\n",
    "            return level\n",
    "    return 'Unknown'\n",
    "\n",
    "def classify_by_flesch(flesch_score):\n",
    "    if flesch_score >= 70:\n",
    "        return 'Beginner'\n",
    "    elif 50 <= flesch_score < 70:\n",
    "        return 'Intermediate'\n",
    "    else:\n",
    "        return 'Advanced'\n",
    "\n",
    "def calculate_complexity(title, description):\n",
    "    full_text = (title + \" \" + description).strip()\n",
    "    complexity = classify_by_keywords(full_text, keywords)\n",
    "    if complexity == 'Unknown':\n",
    "        flesch_score = textstat.flesch_reading_ease(full_text)\n",
    "        complexity = classify_by_flesch(flesch_score)\n",
    "    return complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2VZunTo9ZxD"
   },
   "outputs": [],
   "source": [
    "#Adding Complexity Column to existing table 'books'\n",
    "def add_complexity_column(cursor):\n",
    "    add_column_command = \"\"\"\n",
    "    ALTER TABLE new_merged_books\n",
    "    ADD COLUMN IF NOT EXISTS Complexity VARCHAR(50);\n",
    "    \"\"\"\n",
    "    cursor.execute(add_column_command)\n",
    "    conn.commit()\n",
    "    print(\"Complexity column added successfully\")\n",
    "\n",
    "def update_book_complexity(cursor):\n",
    "    # Fetch all book titles and descriptions\n",
    "    cursor.execute(\"SELECT id, Title, Description FROM books;\")\n",
    "    books = cursor.fetchall()\n",
    "\n",
    "    for book_id, title, description in books:\n",
    "        title = title if title else \"\"\n",
    "        description = description if description else \"\"\n",
    "        complexity = calculate_complexity(title, description)\n",
    "        update_query = \"\"\"\n",
    "        UPDATE new_merged_books\n",
    "        SET Complexity = %s\n",
    "        WHERE id = %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(update_query, (complexity, book_id))\n",
    "    conn.commit()\n",
    "    print(\"Complexity updated for all books\")\n",
    "\n",
    "add_complexity_column(cursor)\n",
    "update_book_complexity(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdWg_rmR-iwj"
   },
   "source": [
    "# Online Courses Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnzVspl3-DDw"
   },
   "outputs": [],
   "source": [
    "# Creating the 'online_courses' table in the database\n",
    "from flask import Flask, request, render_template, jsonify\n",
    "import requests\n",
    "import psycopg2\n",
    "import operator\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "DB_HOST = \"isrpeer.ctw842oc69v3.us-east-2.rds.amazonaws.com\"\n",
    "DB_NAME = \"isr_books\"\n",
    "DB_USER = \"isr_peer\"\n",
    "DB_PASS = \"ISRpeer2024\"\n",
    "\n",
    "def connect():\n",
    "    conn_string = f\"host={DB_HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASS}\"\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()\n",
    "    return conn, cursor\n",
    "\n",
    "def create_online_courses_table(cursor):\n",
    "    create_table_command = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS new_merged_course (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        title VARCHAR(255),\n",
    "        url TEXT,\n",
    "        description TEXT,\n",
    "        headline TEXT,\n",
    "        num_subscribers INT,\n",
    "        avg_rating REAL,\n",
    "        num_reviews INT,\n",
    "        published_title TEXT,\n",
    "        primary_category VARCHAR(255),\n",
    "        primary_subcategory VARCHAR(255),\n",
    "        num_quizzes INT,\n",
    "        num_lectures INT,\n",
    "        num_curriculum_items INT,\n",
    "        visible_instructors TEXT[],\n",
    "        is_paid BOOLEAN,\n",
    "        price VARCHAR(50),\n",
    "        what_you_will_learn TEXT[],\n",
    "        who_should_attend TEXT[],\n",
    "        image_480x270 TEXT,\n",
    "        image_50x50 TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_command)\n",
    "    conn.commit()\n",
    "    print(\"Online courses table created successfully\")\n",
    "\n",
    "create_online_courses_table(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPurEFDL_fHT"
   },
   "outputs": [],
   "source": [
    "# Extracting Data from Udemy API\n",
    "def extract_and_insert_course_data(course, cursor, conn):\n",
    "    # Define default values or handle missing keys gracefully\n",
    "    title = course.get('title', 'N/A')\n",
    "    url = course.get('url', 'N/A')\n",
    "    description = course.get('description', 'N/A')\n",
    "    headline = course.get('headline', 'N/A')\n",
    "    num_subscribers = course.get('num_subscribers', 0)\n",
    "    avg_rating = course.get('avg_rating', 0.0)\n",
    "    num_reviews = course.get('num_reviews', 0)\n",
    "    published_title = course.get('published_title', 'N/A')\n",
    "    primary_category = course.get('primary_category', 'N/A')\n",
    "    primary_subcategory = course.get('primary_subcategory', 'N/A')\n",
    "    num_quizzes = course.get('num_quizzes', 0)\n",
    "    num_lectures = course.get('num_lectures', 0)\n",
    "    num_curriculum_items = course.get('num_curriculum_items', 0)\n",
    "    visible_instructors = [instructor.get('name', 'N/A') for instructor in course.get('visible_instructors', [])]\n",
    "    is_paid = course.get('is_paid', False)\n",
    "    price = course.get('price', 'N/A')\n",
    "    what_you_will_learn = course.get('what_you_will_learn_data', {}).get('items', [])\n",
    "    who_should_attend = course.get('who_should_attend_data', {}).get('items', [])\n",
    "    image_480x270 = course.get('image_480x270', 'N/A')\n",
    "    image_50x50 = course.get('image_50x50', 'N/A')\n",
    "\n",
    "    course_data = (\n",
    "        title, url, description, headline, num_subscribers, avg_rating, num_reviews,\n",
    "        published_title, primary_category, primary_subcategory, num_quizzes, num_lectures,\n",
    "        num_curriculum_items, visible_instructors, is_paid, price, what_you_will_learn,\n",
    "        who_should_attend, image_480x270, image_50x50\n",
    "    )\n",
    "\n",
    "    insert_query = '''\n",
    "    INSERT INTO new_merged_course (\n",
    "        title, url, description, headline, num_subscribers, avg_rating, num_reviews,\n",
    "        published_title, primary_category, primary_subcategory, num_quizzes, num_lectures,\n",
    "        num_curriculum_items, visible_instructors, is_paid, price, what_you_will_learn,\n",
    "        who_should_attend, image_480x270, image_50x50\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    '''\n",
    "    cursor.execute(insert_query, course_data)\n",
    "    conn.commit()\n",
    "\n",
    "class Udemy(object):\n",
    "    __BASE_URL = \"https://www.udemy.com/api-2.0/\"\n",
    "\n",
    "    def __init__(self, client_id: str, client_secret: str) -> None:\n",
    "        self.__client_id = client_id\n",
    "        self.__client_secret = client_secret\n",
    "\n",
    "    @property\n",
    "    def url(self) -> str:\n",
    "        return self.__BASE_URL\n",
    "\n",
    "    @property\n",
    "    def client_id(self):\n",
    "        return self.__client_id\n",
    "\n",
    "    @property\n",
    "    def client_secret(self) -> str:\n",
    "        return self.__client_secret\n",
    "\n",
    "    def _get_full_url(self, resource: str, **kwargs) -> str:\n",
    "        url = f\"{self.url}{resource}/?\"\n",
    "        field_string = \"\"\n",
    "\n",
    "        if \"search\" in kwargs:\n",
    "            url += f\"search={kwargs['search']}&\"\n",
    "            del kwargs['search']\n",
    "\n",
    "        for param, value in sorted(kwargs.items(), key=operator.itemgetter(0)):\n",
    "            if param != \"fields\":\n",
    "                if \"category\" in param and \"&\" in value:\n",
    "                    value = value.replace(\" & \", \"+%26+\")\n",
    "                url += f\"{param}={value}&\"\n",
    "            else:\n",
    "                for ele in value:\n",
    "                    object_name = ele[\"Object\"]\n",
    "                    params = \",\".join(\n",
    "                        filter(\n",
    "                            None,\n",
    "                            [\n",
    "                                ele[\"Setting\"],\n",
    "                                \",\".join(ele[\"Additions\"]),\n",
    "                                \",\".join([\"-\" + x for x in ele[\"Minus\"]]),\n",
    "                            ],\n",
    "                        )\n",
    "                    )\n",
    "                    field_string += f\"fields[{object_name}]={params}&\"\n",
    "        url += field_string\n",
    "        return url\n",
    "\n",
    "    @property\n",
    "    def _authentication(self) -> HTTPBasicAuth:\n",
    "        return HTTPBasicAuth(self.client_id, self.client_secret)\n",
    "\n",
    "    def courses(self, search_term=None, page=1, page_size=10, **kwargs):\n",
    "        kwargs['page'] = page\n",
    "        kwargs['page_size'] = page_size\n",
    "\n",
    "        if search_term:\n",
    "            kwargs['search'] = search_term\n",
    "\n",
    "        full_url = self._get_full_url(\"courses\", **kwargs)\n",
    "        response = requests.get(full_url, auth=self._authentication)\n",
    "        return response.json()\n",
    "\n",
    "client_id = \"Your Client ID\"\n",
    "client_secret = \"Your Client Secret\"\n",
    "udemy = Udemy(client_id, client_secret)\n",
    "\n",
    "def search_and_store_courses(search_term, max_courses=1000):\n",
    "    courses_collected = 0\n",
    "    page_number = 1\n",
    "    all_courses_data = []\n",
    "\n",
    "    while courses_collected < max_courses:\n",
    "        page_size = 100\n",
    "        courses_response = udemy.courses(search_term=search_term, page=page_number, page_size=page_size)\n",
    "        courses = courses_response.get('results', [])\n",
    "\n",
    "        if not courses:\n",
    "            break\n",
    "\n",
    "        for course in courses:\n",
    "            if courses_collected >= max_courses:\n",
    "                break\n",
    "            extract_and_insert_course_data(course, cursor, conn)\n",
    "            courses_collected += 1\n",
    "\n",
    "        page_number += 1\n",
    "\n",
    "search_and_store_courses(\"Search Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd89yTznAhsi"
   },
   "outputs": [],
   "source": [
    "# Complexity Level Classification for online_courses\n",
    "from textstat import textstat\n",
    "\n",
    "# Updated keywords for classification\n",
    "keywords = {\n",
    "    'Beginner': [\n",
    "        'introduction', 'beginner', 'intro', 'basics', 'fundamentals', 'first steps',\n",
    "        'novice', 'entry level', 'starter', 'for newbies', 'basic understanding',\n",
    "        'no experience required', 'zero to hero', 'essentials', '101'\n",
    "    ],\n",
    "    'Intermediate': [\n",
    "        'intermediate', 'next steps', 'beyond basics', 'improve', 'building skills',\n",
    "        'skill enhancement', 'expand knowledge', 'hands-on learning', 'practical',\n",
    "        'deep dive', 'more complex', 'detailed', 'proficiency'\n",
    "    ],\n",
    "    'Advanced': [\n",
    "        'advanced', 'expert level', 'masterclass', 'advanced techniques', 'specialization',\n",
    "        'in-depth', 'high-level', 'complex', 'intensive', 'for professionals', 'expertise',\n",
    "        'thorough understanding', 'comprehensive coverage', 'deep understanding'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Complexity calculation functions remain unchanged\n",
    "def classify_by_keywords(text, keywords):\n",
    "    text = text.lower()\n",
    "    for level, keys in keywords.items():\n",
    "        if any(key in text for key in keys):\n",
    "            return level\n",
    "    return 'Unknown'\n",
    "\n",
    "def classify_by_flesch(flesch_score):\n",
    "    if flesch_score >= 70:\n",
    "        return 'Beginner'\n",
    "    elif 50 <= flesch_score < 70:\n",
    "        return 'Intermediate'\n",
    "    else:\n",
    "        return 'Advanced'\n",
    "\n",
    "def calculate_complexity(title, headline, description, what_you_will_learn, who_should_attend):\n",
    "    # Combine the strings with a space to ensure separation between content from different fields\n",
    "    full_text = \" \".join([title, headline, description, what_you_will_learn, who_should_attend]).strip()\n",
    "    complexity = classify_by_keywords(full_text, keywords)\n",
    "    if complexity == 'Unknown':\n",
    "        flesch_score = textstat.flesch_reading_ease(full_text)\n",
    "        complexity = classify_by_flesch(flesch_score)\n",
    "    return complexity\n",
    "\n",
    "def update_online_complexity(cursor):\n",
    "    cursor.execute(\"SELECT id, title, headline, description, what_you_will_learn, who_should_attend FROM new_merged_course;\")\n",
    "    books = cursor.fetchall()\n",
    "\n",
    "    for book_id, title, headline, description, what_you_will_learn, who_should_attend in books:\n",
    "        title = title if title else \"\"\n",
    "        headline = headline if headline else \"\"\n",
    "        description = description if description else \"\"\n",
    "        what_you_will_learn = what_you_will_learn if what_you_will_learn else \"\"\n",
    "        who_should_attend = who_should_attend if who_should_attend else \"\"\n",
    "\n",
    "        # Calculate complexity based on combined text fields\n",
    "        complexity = calculate_complexity(title, headline, description, what_you_will_learn, who_should_attend)\n",
    "        update_query = \"\"\"\n",
    "        UPDATE new_merged_course\n",
    "        SET Complexity = %s\n",
    "        WHERE id = %s;\n",
    "        \"\"\"\n",
    "        cursor.execute(update_query, (complexity, book_id))\n",
    "    conn.commit()\n",
    "    print(\"Complexity updated for all new_merged_course\")\n",
    "\n",
    "def add_complexity_column_online(cursor):\n",
    "    add_column_command = \"\"\"\n",
    "    ALTER TABLE new_merged_course\n",
    "    ADD COLUMN IF NOT EXISTS Complexity VARCHAR(50);\n",
    "    \"\"\"\n",
    "    cursor.execute(add_column_command)\n",
    "    conn.commit()\n",
    "    print(\"Complexity column added successfully\")\n",
    "\n",
    "add_complexity_column_online(cursor)\n",
    "update_online_complexity(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA82YDvcEQYe"
   },
   "source": [
    "# Tokenization for Full text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBCbYpl8BX78"
   },
   "outputs": [],
   "source": [
    "# books table\n",
    "cursor.execute(\"\"\"\n",
    "    ALTER TABLE new_merged_books ADD COLUMN ts tsvector\n",
    "    GENERATED ALWAYS AS (\n",
    "        setweight(to_tsvector('english', coalesce(title, '')), 'A') ||\n",
    "        setweight(to_tsvector('english', coalesce(description, '')), 'B')\n",
    "    ) STORED;\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "\n",
    "# online courses table\n",
    "cursor.execute(\"\"\"\n",
    "    ALTER TABLE new_merged_course ADD COLUMN ts tsvector\n",
    "    GENERATED ALWAYS AS (\n",
    "        setweight(to_tsvector('english', coalesce(title, '')), 'A') ||\n",
    "        setweight(to_tsvector('english', coalesce(headline, '')), 'A') ||\n",
    "        setweight(to_tsvector('english', coalesce(primary_category, '')), 'B') ||\n",
    "        setweight(to_tsvector('english', coalesce(primary_subcategory, '')), 'B') ||\n",
    "        setweight(to_tsvector('english', coalesce(description, '')), 'C')\n",
    "    ) STORED;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
